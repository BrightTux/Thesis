
The use of video data as a means of surveillance is no longer a new idea. It is no secret that video data could potentially provide invaluable information when dealing with analytic, surveillance or security matters. Millions, if not trillions of video footage are recorded by the second. While there has been various works on extraction of human behaviours in a general surveillance setting especially over the recent years, not much work has focused on car park surveillance scenario. The abundance of raw video data calls for an efficient way of dissecting these raw data while extracting useful information which are easily interpretable, and at the same time, enabling the ease of fetching these information as and when it is required. 

The contribution of this work is twofold. First, a framework for the extraction of colour, motion, timestamp, and size information from the video is proposed. 
%In order to extract the color information from the vehicles, 
The proposed method employs an algorithm that averages out the dominant colour over the course of tracking it and ranking it against different hues. 
%This is a challenging task as outdoor scenarios are often non-ideal due to its ever-changing illumination and weather conditions which would directly affect the accuracy of the colors of the vehicles. 
As for the motion of the vehicles, the proposed method compiles the relative position/location of each vehicles into trajectory sets. In this work, the timestamp information as well as the object size along with the object types were also extracted. A spatio-temporal cube design was adopted to uniquely identify each video footage so that the extracted information can be stored while maintaining the ability to identify them.  

Next, the second contribution of this work is the construction of a retrieval engine which is used to retrieve video shots based on the given semantics which were extracted. This work proposed an unconventional yet intuitive trajectory input in the form of user-described trajectory drawn on the search canvas. 
The other semantics (colour \& timestamp information) were given as keyword-based inputs for the proposed method to locate and rank video shots based on its similarity. 
%As with any large scale retrieval engine, collecting all the ground truth data is not a viable option. Therefore, 
The proposed method is then tested against semantics extracted from a month's worth of data 
%under various lighting and weather conditions 
using the average Precision@K and the normalised Discounted Cumulative Gain (nDCG) metrics. The proposed method managed to achieved the best precision score of 86\%. Likewise for the vehicle colours, the best precision achieved was recorded at 91\%. The average nDCG results scored around the 83\% region for both trajectories and colour results. 
%As a whole, the proposed method shows promising results as it is fairly accurate, fast, and robust under various test scenarios.

This thesis highlights an overall framework of automating and translating existing raw video data into sets of intuitive and useful semantics which can be queried from. Contrary to traditional approach which are labour intensive and time consuming, the proposed method effectively saves time, reduces the cost of manual extraction when retrieving desired video shots accurately, fast and robust under various test scenarios. As the proposed retrieval method utilises point-based data, this algorithms used in this work can also be extended to datasets of similar nature.


%\keywords{Vehicle Semantic Extraction, Retrieval Systems, Carpark Surveillance}